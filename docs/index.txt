
petl - Extract, Transform and Load (Tables of Data)
===================================================

`petl` is a tentative Python package for extracting, transforming and
loading tables of data.

Introduction
------------

There are already many Python packages that are useful for ETL
tasks. However, none (that I've found) cover the full range of
transformations I've needed. Also, many use different data structures
or interfaces to represent tables of data, meaning that functions from
different packages cannot easily be mixed.

It would be magnificent if there was a single Python package that
brought all of this together. However, that's a big ask. In the
interim, it would be wonderful if there was some consistency across
relevant packages so that, over time, an ecosystem of compatible
Python ETL components could emerge.

Status
------

Currently, this package is somewhere between pipe dream, fantasy,
wishlist, experiment, placeholder (until someone with far more talent,
time and energy than me comes along) and call to arms.

However, I would like to do at least the following:

- Try to compile a consistent glossary/terminology for describing
  transformations on tables of data (e.g., what do "map", "cut",
  "slice", , "join", "merge", "fold", "transpose", "split", "melt",
  "cast", ..., mean?) with cross-references to what terminology is
  used in other tools/modules.

- Work towards an interface/protocol for objects that can consume
  and/or generate tabular data, that is (a) as simple as possible, so
  that writing transformation scripts, and developing new
  transformation functions, is possible for people like me (who aren't
  Python gods), (b) compatible with a wide range of transformations,
  (c) compatible with chaining/pipelining multiple transformations,
  and (d) workable for transformations on big(-ish) datasets.

- Explore and develop a deeper understanding of implementation
  strategies for a range of tabular data transformations.

If any of this is in any way interesting to you, then I've set up a
mailing list at http://groups.google.com/group/python-etl - not just
for this package, but for general discussion about Pythonic ways of
working with table-shaped data. Feel free to jump in, or to redirect
me to other projects or forums that have already got this all covered.

Design Goals
------------

Usability
~~~~~~~~~

Many of the big ETL platforms like Talend, Clover and Kettle sell
themselves on having GUIs for designing data transformation
pipelines. You don't need to write code, you just need to point and
click. However, I've found that these GUIs can have a steep learning
curve. They can also obfuscate many of the details of what's going on
under the hood - details that you inevitably need to learn about
anyway, when you get into any fairly complicated transformation task.

This may seem like a contradiction in terms, but I think that, for
many data transformation tasks, a simple Python script or interactive
session, using a simple library of ETL functions, would be more usable
than many ETL GUIs. It could present a lower barrier to entry,
especially for those with a little scripting already under their
belt. It could also be easier to interpret/understand, and scale
better to complicated multi-step transformations (where tens to
hundreds of nodes and arcs on a screen gets cumbersome).

This focus on usability is something that I applaud in tools like
Google Refine and Data Wrangler. One day soon someone will get the GUI
right. Until then, a simple and comprehensive Python DSL or family of
compatible libraries for scripting data transformation tasks would be
very helpful.

Good with Bad Data
~~~~~~~~~~~~~~~~~~

Many tools I've seen for transforming tabular data require the inputs
and outputs to each transformation component to be well defined in
advance, in terms of having a fixed schema (field names and datatypes)
at both ends. While this makes sense and is necessary for some types
of transformation, it is often a burden, and a barrier to working with
less-than-perfect data. So I'd like a tool that is as forgiving as
possible, and demands consistency only when it is absolutely
necessary.

Support an Exploratory Style
~~~~~~~~~~~~~~~~~~~~~~~~~~~~

I work in a world of perpetual heterogeneity. Every day we encounter a
wierd and wonderful new dataset. So the bias is much more towards
one-off transformations. I.e., we are **not** designing transformation
jobs that, once written, will be run nightly for 2 years to integrate
sales and inventory data. We write many transformations, most of which
will be run a handful of times at most.

In this environment, every dataset is an exploration. And
transformations on those data are approached in an exploratory
way. The tools we use need to be written with this in mind.

Focus on Transformation
~~~~~~~~~~~~~~~~~~~~~~~

I'm most interested in the T of ETL. I.e., data
transformations. Writing code to extract/load data from files or
databases is fairly straightforward. However, while some
transformations are fairly easy to code from scratch, others are a bit
mind-bending. This is where a comprehensive library of transformation
functions would be a huge boon.

Contents
--------

.. toctree::
   :maxdepth: 2

   glossary
   protocol
   related_work

Indices and tables
==================

* :ref:`genindex`
* :ref:`modindex`
* :ref:`search`

