.. py:module:: petl

petl - Extract, Transform and Load (Tables of Data)
===================================================

`petl` is a tentative Python package for extracting, transforming and
loading tables of data.

- Documentation: http://petl.rtfd.org/
- Source Code: https://github.com/alimanfoo/petl
- Download: http://pypi.python.org/pypi/petl
- Mailing List: http://groups.google.com/group/python-etl 

Table containers and iterators
------------------------------

This package defines the following convention for objects acting as
containers of tabular data and supporting row-oriented iteration over
the data.

A *table container* (or simply a *table*) is any object which
satisfies the following:

1. implements the `__iter__` method

2. `__iter__` returns a *table iterator* (see below)

3. all iterators returned by `__iter__` are independent, i.e., consuming items from one iterator will not affect any other iterators

(Point 3 ensures that a table can be iterated over any number of times
within the same script or interactive session.)

A *table iterator* is an iterator which satisfies the following:

4. each item returned by the iterator is either a list or a tuple

5. the first item returned by the iterator is a header row comprising a list or tuple of *fields*

6. each subsequent item returned by the iterator is a *data row* comprising a list or tuple of *data values*

7. a *field* is typically a string (`str` or `unicode`) but may be an object of any type as long as it implements `__str__` and is pickleable

8. a *data value* is any pickleable object

So, for example, the list of lists shown below is a table::

>>> table = [['foo', 'bar'], ['a', 1], ['b', 2]]

Note that, under this convention, an object returned by the
`csv.reader` function from the standard Python `csv` module is *not* a
table, because it can only be iterated over once, e.g.::

 >>> from StringIO import StringIO
 >>> import csv
 >>> csvdata = """foo,bar
 ... a,1
 ... b,2
 ... """
 >>> notatable = csv.reader(StringIO(csvdata))
 >>> for row in notatable:
 ...     print row
 ... 
 ['foo', 'bar']
 ['a', '1']
 ['b', '2']
 >>> for row in notatable:
 ...     print row
 ... 
 >>> # can only iterate over notatable once

However, it is straightforward to define functions that support the
above convention and provide access to data from CSV or other types of
file or data source, see e.g. the `fromcsv` function in this package.

The main reason for requiring that tables support independent
iterators is that data from a table may need to be iterated over
several times. E.g., when using `petl` in interactive mode to build up
a sequence of data transformation steps, the user might want to
examine outputs from intermediate steps.

Note that this convention does not place any restrictions on the
lengths of header and data rows. A table may return a header row
and/or data rows of varying lengths. 

Caching / memoization
---------------------

This package tries to make efficient use of memory by using iterators
and lazy evaluation where possible. However, some transformations
cannot be done without building data structures, either in memory or
on disk.

An example is the `sort` function, which will either sort a table
entirely in memory, or will sort the table in memory in chunks,
writing chunks to disk and performing a final merge sort on the
chunks. Which strategy is used will depend on the arguments passed
into the `sort` function when it is called. 

In either case, the sorting can take some time, and if the sorted data
will be used more than once, it is obviously undesirable to throw away
the sorted data and start again from scratch each time. It is better
to cache (a.k.a., memoize) the sorted data, if possible, so it can be
re-used. However, if a table upstream of the sort is mutable, there
needs to be some way of discovering whether data have been changed
since the last sort was performed, and hence whether the cached data
are still fresh or not.

There are also cases where, even though data are generated in a purely
iterative fashion, some programs may still want to cache some or all
of the data. E.g., where data are calculated dynamically and are
relatively expensive to compute, or require scanning many rows, or
where data are being retrieved via a network and there is
latency. Again, there needs to be some way of finding out whether
cached data are fresh or not.

To support caching, it is recommended (but not required) that table
container objects also implement the `cachetag` method. This method
should return an integer which changes whenever the table's fields or
data changes (i.e., a table iterator would yield a different sequence
of items). All `petl` table objects implement this method, where
applicable.

Note that care must be taken to ensure correct implementation of the
`cachetag` method where a table is generating data dynamically from
another source. In these cases, the state of the upstream tables must
be considered when generating a `cachetag` value. One strategy is to
construct `cachetag` values by hashing the internal configuration
attributes of a table, along with the `cachetag` values from any
tables immediately upstream.

In some cases, it may be difficult to determine whether data have
changed, e.g., where data are being retrieved from a database. In
these cases it is suggested that table objects use a user-configurable
time to live (TTL) to generate `cachetag` values. E.g., where a
database table is updated once a day at most, a TTL of a few hours
would enable data to be cached during an interactive session, which
might greatly improve usability for someone developing a
transformation script.

Using `petl` in interactive mode
--------------------------------

TODO

Utility functions
-----------------

.. autofunction:: fields

.. autofunction:: data

.. autofunction:: records

.. autofunction:: count

.. autofunction:: look

.. autofunction:: see

.. autofunction:: values

.. autofunction:: valueset

.. autofunction:: valuecounter

.. autofunction:: valuecounts

.. autofunction:: unique

.. autofunction:: types

.. autofunction:: parsetypes

.. autofunction:: stats

.. autofunction:: rowlengths

.. autofunction:: lookup

.. autofunction:: lookupone

.. autofunction:: recordlookup

.. autofunction:: recordlookupone


Further Reading
---------------

.. toctree::
   :maxdepth: 2

   related_work
   todo

Indices and tables
------------------

* :ref:`genindex`
* :ref:`modindex`
* :ref:`search`
